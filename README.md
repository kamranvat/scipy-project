# Gymnasium RL - CartPole-v1 Performance Measurement

We are measuring and showing the performance of different policies in a Gymnasium Reinforcement Learning environment, specifically using the cartpole-v1 environment.

This project serves as the final project for the Scientific Python course at the University of Osnabrück, summer semester of 2023.


## Table of Contents

- [Goal](#goal)
- [Motivation](#motivation)
- [Installation](#installation)
- [Usage](#usage)
- [Features](#features)
- [Authors](#authors)

## Goal

The goal of this project is to showcase a cool Reinforcement Learning (RL) demo using stable-baselines3. We aim to create visually appealing graphs that display the performance of different RL policies in the cartpole-v1 environment.
We will log the performance data in a csv format, then showcase the results to allow for conclusions about the performance being made.

## Motivation

Reinforcement Learning is a field of study that enables agents to learn and make decisions in dynamic environments. 
By using stable-baselines3 and cartpole-v1, we can demonstrate how different RL algorithms perform on a classic control problem. 
This allows us to apply our Scientific Python skills to a well-studied, yet interesting group of problems.

## Installation

Instructions on how to install your project. Include prerequisites, virtual environment setup, and any required dependencies.

## Usage

Provide examples and instructions on how to use your Python project. Include code snippets and explanations to guide users through the functionalities.
### Explanation

### Command line arguments

### Saving and loading

## Features

- List the main features of your project.
- Feature 1
- Feature 2
- ...


## Authors

- [Christian Meißner](https://github.com/christian-meissner) - chrmeissner@uos.de
- [Kamran Vatankhah](https://github.com/kamranvat) - kvatankhahba@uos.de




